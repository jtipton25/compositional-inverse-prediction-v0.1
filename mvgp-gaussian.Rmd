---
title: "Multivariate Gaussian Process"
author: "John Tipton"
date: "July 27, 2016"
output:
  html_document: default
  pdf_document:
    dev: pdf
    fig_caption: yes
    includes:
      in_header: header.tex
    keep_tex: yes
    number_section: yes
    template: myTemplate.tex
geometry: margin=1in
csl: apa.csl
bibliography: multivariate-gaussian-process.bib
---

## To Do
- figure out convergence issue with mu and eta_star

## Model


```{r setup, tidy=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=6, include=FALSE, eval=TRUE}
set.seed(101)
library(knitr)
library(mvnfast)
library(ggplot2)
library(ggmcmc)
library(Matrix)
library(fields)
library(MCMCpack)
library(coda)
library(snowfall)
library(parallel)
library(rlecuyer)
library(xtable)
library(reshape2)
library(data.table)
library(reshape2)
library(randomForest)
library(GGally)
library(DirichletReg)
library(gridExtra)

source("~/functions/multiplot.R")

# n_adapt <- 10
# n_burn <- 10
# n_mcmc <- 10
# n_thin <- 1
n_adapt <- 100000
n_mcmc <- 100000
n_thin <- 100
n_chains <- 4
n_save <- n_mcmc / n_thin
n_samples <- n_chains * n_save
df <- 6
degree <- 3
message <- 1000

  
if (!dir.exists("./figures/")) {
  dir.create("./figures/")
}
if (!dir.exists("./progress/cross-validate/")) {
  dir.create("./progress/cross-validate/")
}
if (!dir.exists("./progress/")) {
  dir.create("./progress/")
}
if (!dir.exists("./model-fit/")) {
  dir.create("./model-fit/")
}
```

```{r simulation, tidy=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.height=3, fig.width=6, include=FALSE, eval=TRUE}
set.seed(141)
N <- 1000
N_obs <- N - 50
d <- 4#20

source("~/mcmcExample/multinomial-probit-regression/make-lkj.R")
eta <- 1
eta_vec <- rep(0, choose(d, 2))
idx_eta <- 0
for (j in 1:d) {
  for (k in 1:(d-j)) {
    eta_vec[idx_eta + k] <- eta + (d - 1 - j) / 2
  }
  idx_eta <- idx_eta + d-j
}
xi <- rep(0, choose(d, 2))
for (i in 1:choose(d, 2)) {
  xi[i] <- 2 * rbeta(1, eta_vec[i], eta_vec[i]) - 1
}
# xi <- rep(0, choose(d, 2))
# for (i in 1:choose(d, 2)) {
#   xi[i] <- 2 * rbeta(1, eta_vec[i], eta_vec[i]) - 1
# }

R <- makeLKJ(xi, d, cholesky = TRUE)
tau <- rgamma(d, 5, 5)
# tau <- c(1, rgamma(d-1, 1, 1))
R_tau <- R %*% diag(tau)
Sigma <- t(R_tau) %*% R_tau

mu <- rnorm(d, 0, 10)
X <- rnorm(N, 0, 20)
sigma2 <- 1#0.125
phi <- 15
epsilon <- matrix(rnorm(N*d, 0, sqrt(sigma2)), N, d)

##
## simulate from the full model
##
# D <- as.matrix(dist(X))
# C <- exp(- D / phi)

# zeta <- t(rmvn(d, rep(0, N), C)) %*% R

##
## Simulate frome the predictive process model
## 

n_knots <- 30
X_knots <- seq(min(X), max(X), length=n_knots)
# X_knots <- seq(min(X)-1.25*sd(X), max(X)+1.25*sd(X), length=n_knots)
D_knots <- as.matrix(dist(X_knots))               ## distance among knots
D_interpolate <- as.matrix(rdist(X, X_knots))     ## distance from observed 
                                                  ## locations to knots
C_knots <- exp(- D_knots / phi)
C_knots_inv <- solve(C_knots)
c_knots <- exp( - D_interpolate / phi)
Z_knots <- c_knots %*% C_knots_inv
zero_knots <- rep(0, n_knots)
eta_star <- t(rmvn(d, zero_knots, chol(C_knots), isChol=TRUE))
zeta <- Z_knots %*% eta_star %*% R_tau

y <- t(mu + t(zeta)) + epsilon
```


```{r}
simPlotData <- data.frame(species=as.factor(rep(1:4, each=N)), 
                          response=c(y), 
                          covariate=rep(X, times=d), 
                          zeta=c(t(mu + t(zeta))))
# simPlotData <- data.frame(species=as.factor(rep(1:4, each=N)), 
#                           response=c(y[, c(1, 5, 10, 16)]), 
#                           covariate=rep(X, times=d), 
#                           zeta=c(t(mu + t(zeta))[, c(1, 5, 10, 16)]))

gsim1 <- ggplot(simPlotData, aes(x=covariate, y=response, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("Gaussian MVGP") + 
  geom_line(aes(x=covariate, y=zeta, col = species), simPlotData, lwd=1)

gsim2 <- ggplot(simPlotData, aes(x=covariate, y=response, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("Gaussian MVGP by dimension") + 
  geom_line(aes(x=covariate, y=zeta, col = species), simPlotData, lwd=1) + 
  facet_wrap( ~ species, ncol = 2) + 
  theme(axis.text.x=element_blank(), axis.text.y=element_blank(),
        axis.ticks.x=element_blank(), axis.ticks.y=element_blank())
# source("~/functions/multiplot.R")
# png(file="~/mvgp/figures/simulation.png",
#     width=6, height=3, units="in", res=400)
multiplot(gsim1, gsim2, cols=2)
# dev.off()

```
<!-- ![](~/mvgp/figures/simulation.png) -->

```{r fitSim, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE}
if (file.exists("~/mvgp/model-fit/fitSim.RData")) {
  ## Load MCMC run
  load("~/mvgp/model-fit/fitSim.RData")
} else {
  
  ## 
  ## Long running MCMC 
  ##
  
  ## Define parameters 
  params <- list(n_adapt=n_adapt, n_mcmc=n_mcmc,
                 n_thin=n_thin, N_obs=N_obs, X_knots=X_knots, 
                 message=message, 
                 mu=mu, tau2=tau^2, xi=xi, eta_star=eta_star, phi=phi, sigma2=sigma2, 
                 sample_mu=TRUE, sample_mu_mh=FALSE, 
                 sample_tau2=TRUE, sample_xi=TRUE,
                 sample_eta_star=TRUE, sample_eta_star_mh=FALSE,
                 sample_phi=TRUE, sample_sigma2=TRUE, 
                 sample_X=TRUE, sample_X_mh=FALSE)
  
  parallelChains <- function (n_chains) {
    Rcpp::sourceCpp('~/mvgp/mcmc/mcmc-mvgp.cpp')
    out <- mcmc(mcmcRcpp(y, X, params, n_chain=n_chains, 
                         file_name="progress/sim-fit.txt", 
                         corr_function="exponential"))
  }
  
  ## Initalize multicore
  sfInit(parallel=TRUE, cpus=4)
  sfClusterSetupRNG()
  sfExport("y", "X", "params", "phi")
  sfLibrary(coda)
  
  ## create temporary progress file  
  file.create("./progress/sim-fit.txt")
  
  out <- sfLapply(1:4, parallelChains)
  
  sfStop()

  save(out, X_knots, file="~/mvgp/model-fit/fitSim.RData")
}

```


```{r}
## initialze posterior sample variables
mu_post <- matrix(0, n_samples, d)
eta_star_post <- array(0, dim=c(n_samples, n_knots, d))
zeta_post <-  array(0, dim=c(n_samples, N, d))
phi_post <- rep(0,  n_samples)
sigma2_post <- rep(0,  n_samples)
tau2_post <- matrix(0,  n_samples, d)
X_post <- matrix(0,  n_samples, N-N_obs)
xi_post <- array(0,  dim=c(n_samples, choose(d, 2)))
Omega_post <- array(0, dim=c(n_samples, d, d))
R_post <- array(0, dim=c(n_samples, d, d))

for(i in 1:n_chains){
    mu_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$mu
    eta_star_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$eta_star
    zeta_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$zeta
    phi_post[1:n_save + (i-1)*n_save] <- out[[i]]$phi
    sigma2_post[1:n_save + (i-1)*n_save] <- out[[i]]$sigma2
    tau2_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$tau2
    X_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$X
    xi_post[1:n_save + (i-1)*n_save, ] <- out[[i]]$xi
    R_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$R
    Omega_post[1:n_save + (i-1)*n_save, , ] <- out[[i]]$Omega
}          
```



```{r, eval=TRUE}
source("~/mvgp/functions/convert-to-coda.R")
out <- convert_to_coda(out)
```



```{r}
source("~/mvgp/nimble/functions/make_gelman_rubin.R")
Rhat <- make_gelman_rubin(out)
layout(matrix(1:9, 3, 3))
hist(Rhat[grepl("mu", names(Rhat))], main = "Rhat for mu")
hist(Rhat[grepl("eta_star", names(Rhat))], main = "Rhat for eta_star")
hist(Rhat[grepl("zeta", names(Rhat))], main = "Rhat for zeta")
# hist(Rhat[grepl("epsilon", names(Rhat))], main = "Rhat for epsilon")
hist(Rhat[grepl("tau2", names(Rhat))], main = "Rhat for tau2")
# hist(Rhat[grepl("X", names(Rhat))], main = "Rhat for X")
plot(Rhat[grepl("phi", names(Rhat))], main = "Rhat for phi")
abline(h=1, col='red')
hist(Rhat[grepl("xi", names(Rhat))], main = "Rhat for xi")
hist(Rhat, main="All parameters")
Rhat[!is.finite(Rhat)] <- NA
Rhat[grepl("phi", names(Rhat))]
max(unlist(na.omit(Rhat)))
```


```{r, eval=TRUE}
## 
## Posterior plots
##

layout(matrix(1:9, 3, 3))
matplot(mu_post, type = 'l')
abline(h=mu, col='red', lwd=2)
plot(phi_post, type='l')
abline(h=phi, col='red', lwd=2)
plot(sigma2_post, type='l')
abline(h=sigma2, col='red', lwd=2)
matplot(tau2_post, type='l')
abline(h=tau^2)
matplot(xi_post, type='l')
abline(h=xi, col='red')
matplot(eta_star_post[, , 1], type='l')
# abline(h=eta_star[, 1], col='red', lwd=2)
matplot(eta_star_post[, , 2], type='l')
# abline(h=eta_star[, 2], col='red', lwd=2)
matplot(eta_star_post[, , 3], type='l')
# abline(h=eta_star[, 3], col='red', lwd=2)
# matplot(eta_star_post[, , 4], type='l')
# abline(h=eta_star[, 4], col='red', lwd=2)
matplot(X_post, type='l')
abline(h=X[(N_obs+1):N])
```




```{r, eval=TRUE}
layout(matrix(1:4, 2, 2))
matplot(zeta_post[, 1, ], type='l')
abline(h=zeta[1, ], col='red', lwd=2)
matplot(zeta_post[, 2, ], type='l')
abline(h=zeta[2, ], col='red', lwd=2)
matplot(zeta_post[, 3, ], type='l')
abline(h=zeta[3, ], col='red', lwd=2)
matplot(zeta_post[, 4, ], type='l')
abline(h=zeta[4, ], col='red', lwd=2)
```


```{r, eval=TRUE}
layout(matrix(1:4, 2, 2))
matplot(R_post[, , 1], type='l')
abline(h=R[, 1])
matplot(R_post[, , 2], type='l')
abline(h=R[, 2])
matplot(R_post[, , 3], type='l')
abline(h=R[, 3])
matplot(R_post[, , 4], type='l')
abline(h=R[, 4])
```





```{r, eval=TRUE}
layout(matrix(1:3, 3, 1))
idx <- order(X)
zeta_post_mean <- apply(zeta_post, c(2,3), mean)
matplot(X[idx], zeta_post_mean[idx, ], type='l')
matplot(X[idx], zeta[idx, ], type = 'l')
matplot(X[idx], zeta_post_mean[idx, ] - zeta[idx, ], type = 'l')
```



```{r, eval=TRUE}
layout(matrix(1, 1, 1))
matplot(apply(X_post, 2, mean), type='l',
        ylim=c(-50, 50))
matplot(apply(X_post, 2, quantile, prob = 0.025), 
        type='l', add=TRUE, lty=2)
matplot(apply(X_post, 2, quantile, prob = 0.975), 
        type='l', add=TRUE, lty=2)
# matplot(t(X_post), type='l',
#         col=adjustcolor('black', alpha.f=0.025),
#         main=paste("X acceptance ", round(mean(X_accept), digits=3)))
lines(X[(N_obs+1):N], col = 'red')
# lines(apply(out$X[(n_mcmc/2+1):n_mcmc, ], 2, mean), col='blue')
```

```{r, eval=TRUE}
Omega_post_mean <- matrix(0, d, d)
for (i in 1:n_samples) {
  Omega_post_mean <- Omega_post_mean + 
    1/n_samples * t(R_post[i, , ]) %*% R_post[i, , ]
}

multiplot(ggcorr(data=NULL, cor_matrix=cov2cor(Sigma)), 
          ggcorr(data=NULL, cor_matrix=Omega_post_mean), 
          ggcorr(data=NULL, cor_matrix=Omega_post_mean-cov2cor(Sigma)),
          cols=3)
```



```{r, eval=FALSE}
mu_post_mean <- apply(mu_post, 2, mean)
zeta_post_mean <- apply(zeta_post, c(2, 3), mean)
p_alpha <- matrix(0, N, d)
for (i in 1:N) {
  p_alpha[i, ] <- mu_post_mean + zeta_post_mean[i, ]
  # p_alpha[i, ] <- alpha_post_mean[i, ] / sum(alpha_post_mean[i, ])
}

fitPlotData <- data.frame(species=as.factor(rep(1:d, each=N_obs)), count=c(y[1:N_obs, ]), 
                          depth=rep(X[1:N_obs], times=d), alpha=c(p_alpha[1:N_obs, ]))

g1_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("MVGP vs. depth") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25)

g2_post <- ggplot(fitPlotData, aes(x=depth, y=count, color=species, group=species)) + 
  geom_point(alpha=0.25) + theme(legend.position="none") +
  ggtitle("MVGP vs. depth by species") + 
  geom_line(aes(x=depth, y=alpha, col = species), fitPlotData, lwd=1.25) + 
  facet_wrap( ~ species, ncol = 2)
source("~/functions/multiplot.R")
multiplot(g1_post, g2_post, gsim1, gsim2, cols=2)
```




```{r fitSplineSim, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, eval=TRUE}
if (file.exists("~/mvgp/model-fit/fit-gaussian-gam.RData")) {
  ## Load MCMC run
  load("~/mvgp/model-fit/fit-gaussian-gam.RData")
} else {
  ##
  ## Long running MCMC
  ##

  ## Define parameters
  params <- list(n_adapt=n_adapt, n_mcmc=n_mcmc, df=df,
               degree=degree, N_obs=N_obs, message=message,
               n_thin=n_thin)

  ## Fit MCMC model
  parallelChains <- function (n_chains) {
    # Rcpp::sourceCpp('~/mvgp/mcmc/mcmc-basis-missing-covariate-ess.cpp')
    Rcpp::sourceCpp('~/mvgp/mcmc/mcmc-gam.cpp')
    out <- mcmc( mcmcRcpp(y, X, params, n_chain=n_chains,
                          file_name="progress/sim-gam.txt"))
  }

  ## Initalize multicore
  sfInit(parallel=TRUE, cpus=4)
  sfClusterSetupRNG()
  sfExport("y", "X", "params")
  sfLibrary(coda)

  ## create temporary progress file
  file.create("./progress/sim-gam.txt")

  ## run MCMC
  out_splines <- sfLapply(1:4, parallelChains)

  sfStop()

  save(out_splines, file="~/mvgp/model-fit/fit-gaussian-gam.RData")
}
```


```{r}
## process spline model output
## initialze posterior sample variables
beta_post_splines <- array(0, dim=c(n_samples, df, d))
sigma2_post_splines <- rep(0, n_samples)
X_post_splines <- matrix(0,  n_samples, N-N_obs)

for(i in 1:n_chains){
  beta_post_splines[1:n_save + (i-1)*n_save, , ] <- out_splines[[i]]$beta
  sigma2_post_splines[1:n_save + (i-1)*n_save] <- out_splines[[i]]$sigma2
  X_post_splines[1:n_save + (i-1)*n_save, ] <- out_splines[[i]]$X
}
```



```{r, eval=TRUE}
source("~/mvgp/functions/convert-to-coda.R")
out_splines <- convert_to_coda(out_splines)
```



```{r, eval=TRUE}
source("~/mvgp/nimble/functions/make_gelman_rubin.R")
Rhat_splines <- make_gelman_rubin(out_splines)
layout(matrix(1:6, 3, 2))
hist(Rhat_splines[grepl("alpha", names(Rhat_splines))], main = "Rhat for alpha")
hist(Rhat_splines[grepl("beta", names(Rhat_splines))], main = "Rhat for beta")
hist(Rhat_splines[grepl("sigma2", names(Rhat_splines))], main = "Rhat for sigma2")
hist(Rhat_splines[grepl("X", names(Rhat_splines))], main = "Rhat for X")
hist(Rhat_splines, main="All parameters")
Rhat_splines[!is.finite(Rhat_splines)] <- NA
max(unlist(na.omit(Rhat_splines)))
```


```{r}
##
## evaluate predictive ability
##

Rcpp::sourceCpp("~/testate/functions/makeCRPS.cpp")
CRPS_MVGP <- makeCRPS(X_post, X[(N_obs+1):N], n_save)
X_mean <- apply(X_post, 2, mean)
MSPE_MVGP <- (X_mean -  X[(N_obs+1):N])^2
MAE_MVGP <- abs(apply(X_post, 2, median) - X[(N_obs+1):N])
X_025 <- apply(X_post, 2, quantile, prob = 0.025)
X_975 <- apply(X_post, 2, quantile, prob = 0.975)
coverage_MVGP <- ( X[(N_obs+1):N] >= X_025) & ( X[(N_obs+1):N] <= X_975)

## Spline Model
Rcpp::sourceCpp("~/testate/functions/makeCRPS.cpp")
CRPS_splines <- makeCRPS(X_post_splines, X[(N_obs+1):N], n_save)
X_mean_splines <- apply(X_post_splines, 2, mean)
MSPE_splines <- (X_mean_splines -  X[(N_obs+1):N])^2
MAE_splines  <- abs(apply(X_post_splines, 2, median) -   X[(N_obs+1):N])
X_025_splines <- apply(X_post_splines, 2, quantile, prob = 0.025)
X_975_splines <- apply(X_post_splines, 2, quantile, prob = 0.975)
coverage_splines <- ( X[(N_obs+1):N] >= X_025_splines) & ( X[(N_obs+1):N] <= X_975_splines)


## Random Forest

train <- data.frame(moisture=X[1:N_obs], y[1:N_obs, ])
test <- data.frame(y[(N_obs+1):N, ])
rf <- randomForest(moisture ~ ., data = train)
CRPS_rf <- makeCRPS(t(matrix(predict(rf, test, predict.all=TRUE)$individual,
                             N-N_obs, 500)), X[(N_obs+1):N], 500)
MSPE_rf <- (predict(rf, test) - X[(N_obs+1):N])^2
MAE_rf <- abs(predict(rf, test) - X[(N_obs+1):N])
rf_CI <- t(apply( predict(rf, test, predict.all=TRUE)$individual, 1,
                  function(x) {
                    quantile(x, c(0.025,0.975))
                  }))
coverage_rf <- ((X[(N_obs+1):N] >= rf_CI[, 1]) &
               (X[(N_obs+1):N] <= rf_CI[, 2]))

# CRPS_out <- cbind(CRPS_MVGP, CRPS_splines, MAE_rf)
# MSPE_out <- cbind(MSPE_MVGP, MSPE_splines, MSPE_rf)
# MAE_out <- cbind(MAE_MVGP, MAE_splines, MAE_rf)
# coverage_out <- cbind(coverage_MVGP, coverage_splines, coverage_rf)
# colnames(CRPS_out) <- c("MVGP", "GAM", "RF")
# colnames(MAE_out) <- c("MVGP", "GAM", "RF")
# colnames(MSPE_out) <- c("MVGP", "GAM", "RF")
# colnames(coverage_out) <- c("MVGP", "GAM", "RF")
CRPS_out <- cbind(CRPS_MVGP, CRPS_splines)
MSPE_out <- cbind(MSPE_MVGP, MSPE_splines)
MAE_out <- cbind(MAE_MVGP, MAE_splines)
coverage_out <- cbind(coverage_MVGP, coverage_splines)
colnames(CRPS_out) <- c("MVGP", "GAM")
colnames(MAE_out) <- c("MVGP", "GAM")
colnames(MSPE_out) <- c("MVGP", "GAM")
colnames(coverage_out) <- c("MVGP", "GAM")

CRPS <- data.frame(t(apply(CRPS_out, 2, mean)))
MSPE <- data.frame(t(apply(MSPE_out, 2, mean)))
MAE <- data.frame(t(apply(MAE_out, 2, mean)))
coverage <- data.frame(100/(N-N_obs)*t(apply(coverage_out, 2, sum)))

sim_results <- rbind(CRPS, MSPE, MAE, coverage)
rownames(sim_results) <- c("CRPS", "MSPE", "MAE", "95% CI coverage rates")
print(xtable(sim_results, digits=4), file="results/sim-gaussian.tex",
      floating=FALSE)
```

```{r}
kable(sim_results)
```


